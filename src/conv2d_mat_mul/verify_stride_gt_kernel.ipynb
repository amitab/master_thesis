{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class conv2d:\n",
    "    def __init__(self, k, s, p):\n",
    "        self.k = k\n",
    "        self.p = p\n",
    "        self.s = s\n",
    "\n",
    "    def get_x(self):\n",
    "        return self.X + self.p * 2\n",
    "\n",
    "    def get_y(self):\n",
    "        return self.Y + self.p * 2\n",
    "\n",
    "    def get_slides_done(self):# Find slides that are done already\n",
    "        cols_done = self.y_id * self.y_size + self.p\n",
    "        h_slides_done = max(math.floor((cols_done-self.k)/self.s) + 1, 0)\n",
    "        rows_done = self.x_id * self.x_size + self.p\n",
    "        v_slides_done = max(math.floor((rows_done-self.k)/self.s) + 1, 0)\n",
    "\n",
    "        # Windows done so far\n",
    "        return (v_slides_done, h_slides_done)\n",
    "\n",
    "    def get_block_win_val(self, w, i, j, ch, imgs, img):\n",
    "        cols_done = self.y_id * self.y_size + self.p\n",
    "        rows_done = self.x_id * self.x_size + self.p\n",
    "\n",
    "        h_slides = math.floor((self.get_y()-self.k)/self.s) + 1\n",
    "        v_slides = math.floor((self.get_x()-self.k)/self.s) + 1\n",
    "\n",
    "        r = math.floor(w / h_slides)\n",
    "        c = w % h_slides\n",
    "        x = (r * self.s) + i\n",
    "        y = (c * self.s) + j\n",
    "\n",
    "        print(\"ORIGIN: \", r * self.s ,c * self.s , \"COORD:\", x,y, \"TCOORD: \", x-rows_done, y-cols_done)\n",
    "        x -= rows_done\n",
    "        y -= cols_done\n",
    "\n",
    "        if x < 0 or y < 0 or x >= self.b_X or y >= self.b_Y:\n",
    "            return 0\n",
    "\n",
    "        return imgs[img][ch][x][y]\n",
    "\n",
    "    def img_block_to_conv2d(self, imgs, X, Y, x_id, y_id, x_size, y_size):\n",
    "        self.channels, self.b_X, self.b_Y = imgs[0].shape\n",
    "        self.X, self.Y, self.x_id, self.y_id, self.x_size, self.y_size = X, Y, x_id, y_id, x_size, y_size\n",
    "        \n",
    "        cols_done = self.y_id * self.y_size\n",
    "        rows_done = self.x_id * self.x_size\n",
    "\n",
    "        h_slides = math.floor((self.get_y()-self.k)/self.s) + 1\n",
    "        v_slides = math.floor((self.get_x()-self.k)/self.s) + 1\n",
    "\n",
    "        v_cols = cols_done + self.b_Y + self.p\n",
    "        v_rows = rows_done + self.b_X + self.p\n",
    "        if cols_done + self.b_Y >= Y:\n",
    "            v_cols += self.p\n",
    "        if rows_done + self.b_X >= X:\n",
    "            v_rows += self.p\n",
    "\n",
    "        h_vslides = max(math.floor((v_cols - self.k)/self.s) + 1, 0)\n",
    "        v_vslides = max(math.floor((v_rows - self.k)/self.s) + 1, 0)\n",
    "        \n",
    "        if cols_done + self.b_Y < Y:\n",
    "            diff = math.ceil((v_cols - (h_vslides - 1) * self.s) / self.s) - 1\n",
    "            h_vslides += diff\n",
    "        if rows_done + self.b_X < X:\n",
    "            diff = math.ceil((v_rows - (v_vslides - 1) * self.s) / self.s) - 1\n",
    "            v_vslides += diff\n",
    "        \n",
    "        print(\"Virtual matrix slides \", h_vslides, v_vslides)\n",
    "\n",
    "        v_done, h_done = self.get_slides_done()\n",
    "        print(\"Starting window \", v_done, h_done)\n",
    "\n",
    "        data = {}\n",
    "        for x in range(v_done, v_vslides):\n",
    "            for y in range(h_done, h_vslides):\n",
    "                print(\"Looking at window \", x * h_slides + y)\n",
    "                row = []\n",
    "                for c in range(self.channels):\n",
    "                    for i in range(self.k):\n",
    "                        for j in range(self.k):\n",
    "                            row.append(self.get_block_win_val(x * h_slides + y, i, j, c, imgs, 0))\n",
    "                data[x * h_slides+ y] = np.array(row)\n",
    "\n",
    "        return data\n",
    " \n",
    "    def aggregate(self, datas):\n",
    "        fin = {}\n",
    "        for partial in datas:\n",
    "            for window in partial:\n",
    "                if window in fin:\n",
    "#                     for i in range(len(fin[window])):\n",
    "#                         if fin[window][i] == 0:\n",
    "#                             fin[window][i] = partial[window][i]\n",
    "#                         else:\n",
    "#                             assert fin[window][i] == partial[window][i]\n",
    "                    fin[window] += partial[window]\n",
    "                else:\n",
    "                    fin[window] = partial[window]\n",
    "        res = [fin[d] for d in range(len(fin))]\n",
    "        return np.array(res)\n",
    "\n",
    "    def get_win_val(self, w, i, j, ch, imgs, img):    \n",
    "        h_slides = math.floor((self.get_y()-self.k)/self.s) + 1\n",
    "        v_slides = math.floor((self.get_x()-self.k)/self.s) + 1\n",
    "\n",
    "        r = math.floor(w / h_slides)\n",
    "        c = w % h_slides\n",
    "        x = (r * self.s) + i - self.p\n",
    "        y = (c * self.s) + j - self.p\n",
    "\n",
    "        print(\"ORIGIN: \", r * self.s ,c * self.s , \"COORD:\", x,y)\n",
    "        if x < 0 or y < 0 or x >= self.X or y >= self.Y:\n",
    "            return 0\n",
    "\n",
    "        return imgs[img][ch][x][y]\n",
    "    \n",
    "    def img_to_conv2d(self, imgs):\n",
    "        self.channels, self.X, self.Y = imgs[0].shape\n",
    "\n",
    "        h_slides = math.floor((self.get_y()-self.k)/self.s) + 1\n",
    "        v_slides = math.floor((self.get_x()-self.k)/self.s) + 1\n",
    "\n",
    "        windows = h_slides * v_slides\n",
    "\n",
    "        data = []\n",
    "\n",
    "        for w in range(windows):\n",
    "            print(\"Looking at window \", w)\n",
    "            row = []\n",
    "            for c in range(self.channels):\n",
    "                for i in range(self.k):\n",
    "                    for j in range(self.k):\n",
    "                        row.append(self.get_win_val(w, i, j, c, imgs, 0))\n",
    "            data.append(row)\n",
    "\n",
    "        return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at window  0\n",
      "ORIGIN:  0 0 COORD: 0 0\n",
      "ORIGIN:  0 0 COORD: 0 1\n",
      "ORIGIN:  0 0 COORD: 0 2\n",
      "ORIGIN:  0 0 COORD: 1 0\n",
      "ORIGIN:  0 0 COORD: 1 1\n",
      "ORIGIN:  0 0 COORD: 1 2\n",
      "ORIGIN:  0 0 COORD: 2 0\n",
      "ORIGIN:  0 0 COORD: 2 1\n",
      "ORIGIN:  0 0 COORD: 2 2\n",
      "ORIGIN:  0 0 COORD: 0 0\n",
      "ORIGIN:  0 0 COORD: 0 1\n",
      "ORIGIN:  0 0 COORD: 0 2\n",
      "ORIGIN:  0 0 COORD: 1 0\n",
      "ORIGIN:  0 0 COORD: 1 1\n",
      "ORIGIN:  0 0 COORD: 1 2\n",
      "ORIGIN:  0 0 COORD: 2 0\n",
      "ORIGIN:  0 0 COORD: 2 1\n",
      "ORIGIN:  0 0 COORD: 2 2\n",
      "Looking at window  1\n",
      "ORIGIN:  0 4 COORD: 0 4\n",
      "ORIGIN:  0 4 COORD: 0 5\n",
      "ORIGIN:  0 4 COORD: 0 6\n",
      "ORIGIN:  0 4 COORD: 1 4\n",
      "ORIGIN:  0 4 COORD: 1 5\n",
      "ORIGIN:  0 4 COORD: 1 6\n",
      "ORIGIN:  0 4 COORD: 2 4\n",
      "ORIGIN:  0 4 COORD: 2 5\n",
      "ORIGIN:  0 4 COORD: 2 6\n",
      "ORIGIN:  0 4 COORD: 0 4\n",
      "ORIGIN:  0 4 COORD: 0 5\n",
      "ORIGIN:  0 4 COORD: 0 6\n",
      "ORIGIN:  0 4 COORD: 1 4\n",
      "ORIGIN:  0 4 COORD: 1 5\n",
      "ORIGIN:  0 4 COORD: 1 6\n",
      "ORIGIN:  0 4 COORD: 2 4\n",
      "ORIGIN:  0 4 COORD: 2 5\n",
      "ORIGIN:  0 4 COORD: 2 6\n",
      "Looking at window  2\n",
      "ORIGIN:  4 0 COORD: 4 0\n",
      "ORIGIN:  4 0 COORD: 4 1\n",
      "ORIGIN:  4 0 COORD: 4 2\n",
      "ORIGIN:  4 0 COORD: 5 0\n",
      "ORIGIN:  4 0 COORD: 5 1\n",
      "ORIGIN:  4 0 COORD: 5 2\n",
      "ORIGIN:  4 0 COORD: 6 0\n",
      "ORIGIN:  4 0 COORD: 6 1\n",
      "ORIGIN:  4 0 COORD: 6 2\n",
      "ORIGIN:  4 0 COORD: 4 0\n",
      "ORIGIN:  4 0 COORD: 4 1\n",
      "ORIGIN:  4 0 COORD: 4 2\n",
      "ORIGIN:  4 0 COORD: 5 0\n",
      "ORIGIN:  4 0 COORD: 5 1\n",
      "ORIGIN:  4 0 COORD: 5 2\n",
      "ORIGIN:  4 0 COORD: 6 0\n",
      "ORIGIN:  4 0 COORD: 6 1\n",
      "ORIGIN:  4 0 COORD: 6 2\n",
      "Looking at window  3\n",
      "ORIGIN:  4 4 COORD: 4 4\n",
      "ORIGIN:  4 4 COORD: 4 5\n",
      "ORIGIN:  4 4 COORD: 4 6\n",
      "ORIGIN:  4 4 COORD: 5 4\n",
      "ORIGIN:  4 4 COORD: 5 5\n",
      "ORIGIN:  4 4 COORD: 5 6\n",
      "ORIGIN:  4 4 COORD: 6 4\n",
      "ORIGIN:  4 4 COORD: 6 5\n",
      "ORIGIN:  4 4 COORD: 6 6\n",
      "ORIGIN:  4 4 COORD: 4 4\n",
      "ORIGIN:  4 4 COORD: 4 5\n",
      "ORIGIN:  4 4 COORD: 4 6\n",
      "ORIGIN:  4 4 COORD: 5 4\n",
      "ORIGIN:  4 4 COORD: 5 5\n",
      "ORIGIN:  4 4 COORD: 5 6\n",
      "ORIGIN:  4 4 COORD: 6 4\n",
      "ORIGIN:  4 4 COORD: 6 5\n",
      "ORIGIN:  4 4 COORD: 6 6\n",
      "(4, 18)\n",
      "[0.1721199598569213, 0.9426320318379866, 0.6128911065748478, 0.07117905265829205, 0.7704820092300846, 0.6520124643487795, 0.5295659852302752, 0.3040381979042518, 0.4335093924961064, 0.8913378913359435, 0.7645627111645891, 0.13943528305574837, 0.5113054881110293, 0.9464717110672553, 0.4572776650544833, 0.02831595132066278, 0.5781039409681896, 0.015990410032593605]\n",
      "[0.3540005892832828, 0.8821857105192886, 0.7602422384947086, 0.5947689703487031, 0.26307388018812006, 0.41832731343271734, 0.06504280154550013, 0.5637362579924345, 0.834373242373384, 0.66218954528049, 0.9650479898305934, 0.4432204913463432, 0.3215100838276955, 0.4355099773142078, 0.3951422177652879, 0.4566195573219023, 0.012019598086475125, 0.21646650697121883]\n",
      "[0.7201223927727316, 0.29651892015940895, 0.6738472921224422, 0.9698583903912249, 0.8721279984943864, 0.9710253169938474, 0.8090928494884628, 0.5884036247749772, 0.2884265543706017, 0.6751681298332379, 0.38837433439311475, 0.30998821277413713, 0.702926451587562, 0.8849441406084241, 0.78959278774689, 0.5527974227647443, 0.3453418880737117, 0.1664920813659665]\n",
      "[0.7908832721921957, 0.19352641915974134, 0.47420897339224066, 0.11728145964486725, 0.19970419713801413, 0.06918321404576588, 0.7577179894208141, 0.3642343687052586, 0.998319089621357, 0.9203987161059182, 0.17091828248122243, 0.5425741649385175, 0.6656146731907185, 0.9111466637733724, 0.27007769703224493, 0.6576883319407761, 0.02633605608866929, 0.7870547191456594]\n"
     ]
    }
   ],
   "source": [
    "imgs = np.random.rand(1,2,10,10)\n",
    "header = \"{},{},{},{}\".format(*imgs.shape)\n",
    "np.savetxt(\"images_2_10_10.np\", imgs.flatten(), header=header)\n",
    "\n",
    "kernel_size = 3\n",
    "stride = 4\n",
    "padding = 0\n",
    "\n",
    "con = conv2d(kernel_size, stride, padding)\n",
    "data = con.img_to_conv2d(imgs)\n",
    "print(data.shape)\n",
    "for i in range(data.shape[0]):\n",
    "    print(data[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.loadtxt(\"kernel_3.np\").reshape(3,2,3,3)\n",
    "bias = np.loadtxt(\"bias_3.np\").reshape(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [kernel[i].flatten() for i in range(kernel.shape[0])]\n",
    "arr = np.array(arr)\n",
    "arr = arr.T\n",
    "arr = np.vstack((arr, bias.reshape(1, 3)))\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.15348091, 3.73308533, 5.73540866],\n",
       "       [5.26820541, 3.87565422, 5.33113346],\n",
       "       [5.97792431, 4.34766819, 5.74530992],\n",
       "       [5.37354933, 3.8488311 , 5.28647831]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.hstack((data, np.ones(data.shape[0]).reshape(-1, 1)))\n",
    "data@arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "m = torch.nn.Conv2d(2, 3, 3, stride=4, padding=0, bias=True)\n",
    "m.weight = torch.nn.Parameter(torch.tensor(kernel))\n",
    "m.bias = torch.nn.Parameter(torch.tensor(bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[5.1535, 5.2682],\n",
       "          [5.9779, 5.3735]],\n",
       "\n",
       "         [[3.7331, 3.8757],\n",
       "          [4.3477, 3.8488]],\n",
       "\n",
       "         [[5.7354, 5.3311],\n",
       "          [5.7453, 5.2865]]]], dtype=torch.float64,\n",
       "       grad_fn=<ThnnConv2DBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = m(torch.tensor(imgs))\n",
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

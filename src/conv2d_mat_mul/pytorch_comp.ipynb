{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "imgs = np.loadtxt(\"images_1.np\").reshape(1,2,6,6)\n",
    "kernel = np.loadtxt(\"kernel_3.np\").reshape(3,2,3,3)\n",
    "bias = np.loadtxt(\"bias_3.np\").reshape(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.15955306, 0.84906901, 0.54561362, 0.89604376, 0.37660462,\n",
       "          0.32604895],\n",
       "         [0.88536291, 0.72544014, 0.30213657, 0.24391796, 0.8367923 ,\n",
       "          0.00677764],\n",
       "         [0.68139817, 0.45835189, 0.40025061, 0.12925077, 0.38525406,\n",
       "          0.56888845],\n",
       "         [0.61425965, 0.93827786, 0.61741657, 0.25136994, 0.41869429,\n",
       "          0.27364   ],\n",
       "         [0.38343472, 0.52306167, 0.9823107 , 0.95366812, 0.25909526,\n",
       "          0.02918973],\n",
       "         [0.5683895 , 0.60234376, 0.1621629 , 0.32172377, 0.34041692,\n",
       "          0.05159952]],\n",
       "\n",
       "        [[0.09849916, 0.16914041, 0.89250968, 0.5272783 , 0.87366801,\n",
       "          0.12653044],\n",
       "         [0.53313813, 0.95166385, 0.4389646 , 0.65317807, 0.43628923,\n",
       "          0.90843706],\n",
       "         [0.8469585 , 0.43609608, 0.55670027, 0.54856218, 0.8700725 ,\n",
       "          0.60629741],\n",
       "         [0.36392068, 0.24211918, 0.48511723, 0.44674531, 0.06507306,\n",
       "          0.71049912],\n",
       "         [0.49205998, 0.51518035, 0.65234204, 0.20369967, 0.5902329 ,\n",
       "          0.84236075],\n",
       "         [0.15014032, 0.92294339, 0.91016256, 0.91172   , 0.00540243,\n",
       "          0.91656066]]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.96844024, 0.91677037, 0.20084168],\n",
       "         [0.51737026, 0.84232667, 0.16916628],\n",
       "         [0.00337454, 0.52294908, 0.97996873]],\n",
       "\n",
       "        [[0.49270656, 0.28457836, 0.4204916 ],\n",
       "         [0.38666854, 0.74145295, 0.77173518],\n",
       "         [0.16400922, 0.20366011, 0.53234345]]],\n",
       "\n",
       "\n",
       "       [[[0.20287251, 0.63202806, 0.87074152],\n",
       "         [0.50011759, 0.21778542, 0.02711159],\n",
       "         [0.69487962, 0.59547085, 0.4803164 ]],\n",
       "\n",
       "        [[0.3663493 , 0.1255844 , 0.77317302],\n",
       "         [0.00984027, 0.37000069, 0.05565784],\n",
       "         [0.37260327, 0.56026268, 0.10974279]]],\n",
       "\n",
       "\n",
       "       [[[0.37104108, 0.65179618, 0.47142603],\n",
       "         [0.17087244, 0.01127146, 0.12772858],\n",
       "         [0.86150483, 0.8443549 , 0.55282022]],\n",
       "\n",
       "        [[0.71372867, 0.95544612, 0.34553299],\n",
       "         [0.09791882, 0.69473835, 0.28326671],\n",
       "         [0.32258273, 0.91501908, 0.207473  ]]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51915282, 0.34316147, 0.91806065])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.nn.Conv2d(2, 3, 3, stride=1, padding=0, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.1558,  0.1605, -0.1430],\n",
       "          [ 0.0566, -0.0328, -0.1612],\n",
       "          [ 0.1976,  0.1789,  0.0132]],\n",
       "\n",
       "         [[ 0.1641,  0.1708,  0.0081],\n",
       "          [-0.1866,  0.0120, -0.0896],\n",
       "          [-0.1182, -0.0119,  0.0413]]],\n",
       "\n",
       "\n",
       "        [[[-0.0566, -0.2188,  0.0332],\n",
       "          [-0.1253,  0.1270,  0.0139],\n",
       "          [ 0.0202,  0.1869,  0.0645]],\n",
       "\n",
       "         [[-0.1506,  0.2162,  0.0587],\n",
       "          [ 0.2192, -0.1618,  0.2038],\n",
       "          [-0.0360, -0.0764, -0.1507]]],\n",
       "\n",
       "\n",
       "        [[[-0.1537, -0.0689, -0.1462],\n",
       "          [ 0.0412,  0.0924,  0.1329],\n",
       "          [ 0.1857, -0.1544,  0.1913]],\n",
       "\n",
       "         [[-0.1009,  0.1659, -0.0397],\n",
       "          [ 0.1295,  0.1369, -0.1033],\n",
       "          [-0.1086,  0.0813, -0.2039]]]], requires_grad=True)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1514, -0.1043, -0.0578], requires_grad=True)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.weight = torch.nn.Parameter(torch.tensor(kernel))\n",
    "m.bias = torch.nn.Parameter(torch.tensor(bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[0.9684, 0.9168, 0.2008],\n",
       "          [0.5174, 0.8423, 0.1692],\n",
       "          [0.0034, 0.5229, 0.9800]],\n",
       "\n",
       "         [[0.4927, 0.2846, 0.4205],\n",
       "          [0.3867, 0.7415, 0.7717],\n",
       "          [0.1640, 0.2037, 0.5323]]],\n",
       "\n",
       "\n",
       "        [[[0.2029, 0.6320, 0.8707],\n",
       "          [0.5001, 0.2178, 0.0271],\n",
       "          [0.6949, 0.5955, 0.4803]],\n",
       "\n",
       "         [[0.3663, 0.1256, 0.7732],\n",
       "          [0.0098, 0.3700, 0.0557],\n",
       "          [0.3726, 0.5603, 0.1097]]],\n",
       "\n",
       "\n",
       "        [[[0.3710, 0.6518, 0.4714],\n",
       "          [0.1709, 0.0113, 0.1277],\n",
       "          [0.8615, 0.8444, 0.5528]],\n",
       "\n",
       "         [[0.7137, 0.9554, 0.3455],\n",
       "          [0.0979, 0.6947, 0.2833],\n",
       "          [0.3226, 0.9150, 0.2075]]]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.5192, 0.3432, 0.9181], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[5.5627, 5.2637, 5.5086, 5.8179],\n",
       "          [6.1722, 4.9657, 4.2127, 5.1173],\n",
       "          [6.1327, 5.5818, 4.2886, 3.9523],\n",
       "          [5.6042, 5.8132, 4.8795, 4.4901]],\n",
       "\n",
       "         [[4.6851, 4.0191, 4.0644, 3.3213],\n",
       "          [4.1573, 3.9146, 3.5811, 3.2852],\n",
       "          [4.1568, 4.2590, 4.1325, 3.5096],\n",
       "          [4.2057, 4.0203, 3.4149, 3.3140]],\n",
       "\n",
       "         [[5.3470, 5.4767, 5.6353, 5.4309],\n",
       "          [6.1220, 5.5910, 5.0273, 4.7556],\n",
       "          [5.4880, 5.7419, 5.4067, 5.1275],\n",
       "          [5.6648, 5.5148, 4.6167, 3.9603]]]], dtype=torch.float64,\n",
       "       grad_fn=<ThnnConv2DBackward>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = m(torch.tensor(imgs))\n",
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4, 4])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
